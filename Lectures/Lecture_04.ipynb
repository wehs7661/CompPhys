{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-100899e0deea9789",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 4: A lightning overview of statistical mechanics\n",
    "\n",
    "## Physics 7810, Spring 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.1 - Overview \n",
    "\n",
    "In this lecture I'll review some results from statistical mechanics, focusing on those aspects of most relevance to computer simulation. Of particular interest are the various ways we can measure observables in computer simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.2 Subsystems\n",
    "\n",
    "An isolated macroscopic system with fixed $N,V,E$ can be divided into subsystems in thermal, mechanical, or diffusive contact, with $E = E_1 + E_2$, $V = V_1 + V_2$, and $N = N_1 + N_2$.\n",
    "\n",
    "<img src=\"images/Sethna_Fig_3_3.png\" alt=\"Drawing\" style=\"width: 400px;\">\n",
    "\n",
    "Figure from *Statistical Mechanics: Entropy, Order Parameters, and Complexity*, by Jim Sethna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "All of statistical mechanics and thermodynamics can be derived by considering how the *total number of microstates* \n",
    "(*multiplicity*) $\\Omega(N,V,E)$ depends on $E_1$, $V_1$, or $N_1$.\n",
    " \n",
    "Various thermodynamic ensembles are obtained by considering a small subsystem in thermal, mechanical, or diffusive contact with a much larger *reservoir* (of energy, volume, or particles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.3 Basic postulate of statistical mechanics\n",
    "\n",
    "*An isolated system with constant particle particle number $N$, volume $V$, and energy $E$ is equally likely to be found in any of its available microstates*.\n",
    "  \n",
    "The number of microstates corresponding to the macrostate $N,V,E$ is called the *multiplicity*, denoted $\\Omega(N,V,E)$.\n",
    " \n",
    "Given this postulate, the macroscopic properties of a system can be calculated as an unweighted average over the $\\Omega(N,V,E)$ microstates ('microcanonical ensemble').\n",
    " \n",
    "In fact, we can obtain all thermodynamic properties (pressure, chemical potential, ...) from $\\Omega(N,V,E)$ itself, but calculating $\\Omega(N,V,E)$ is hard (except for the classical ideal gas and a few other simple models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Justification for the basic postulate:\n",
    "\n",
    "* Liouville theorem: a uniform phase space density is stationary under Hamiltonian dynamics\n",
    "* Microscopic chaos: mixing flow in phase space causes chaotic systems to evolve toward this stationary state (ergodic hypothesis)\n",
    "* Eigenstate thermalization hypothesis (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.4 Large and very large numbers, entropy\n",
    "\n",
    "\n",
    "The number of atoms in a macroscopic volume of matter is a *large* number:\n",
    " \n",
    "$$N \\sim 10^{23}.$$\n",
    " \n",
    "The multiplicity $\\Omega(N,V,E)$, which measures the number of ways of assigning $N$ particles to available states with total energy $E$, is a *very large* (*combinatorially large*) number:\n",
    " \n",
    "$$\\Omega(N,V,E) \\sim e^N \\sim e^{10^{23}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Such unimaginably large numbers are hard to deal with, so we usually work with their logarithms, which are merely large:\n",
    " \n",
    "$$S(N,V,E) = k_B \\ln \\Omega(N,V,E) \\sim O(N).$$\n",
    " \n",
    "$S(N,V,E)$ is the *entropy*, a logarithmic measure of the number of microstates for a given macrostate $N,V,E$. Boltzmann's constant $k_B$ is introduced for historical and practical reasons.\n",
    " \n",
    "$S(N,V,E)$ usually increases with increasing $N$, $V$, or $E$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.5 Entropy is an extensive quantity\n",
    "\n",
    "Consider an isolated system with total energy $E$ consisting of two weakly coupled subsystems that can exchange energy, whose states can be enumerated independently.\n",
    " \n",
    "The total multiplicity is the product of the multiplicities of the two subsystems, integrated over the energy $E_1$ of system 1:\n",
    " \n",
    "$$\\Omega(E) = \\int_0^E \\Omega_1(E_1) \\Omega_2(E-E_1) dE_1.$$\n",
    " \n",
    "Note that the integrand divided by the total integral is just the probability density for subsystem 1 to have energy $E_1$:\n",
    " \n",
    "$$\\rho(E_1) = \\Omega_1(E_1) \\Omega_2(E-E_1) / \\Omega(E).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For large $N$, the integrand is very sharply peaked around $E_1^{\\rm max}$, with (small) width $\\Delta E_1$, so\n",
    " \n",
    "$$\\Omega(E) \\approx \\Omega_1(E_1^{\\rm max}) \\Omega_2(E-E_1^{\\rm max}) \\Delta E_1.$$\n",
    "(Note: the expression above is based on the property that the distribution is incredibly sharply peaked. To estiamte the area under the curve, only calculating the are of the peak is a simple way. The larger N is, the sharper the peak is. Therefore, this estimation is particularly good for a really large N.) \n",
    "\n",
    "The total entropy is therefore:\n",
    " \n",
    "$$S(E) = k_B \\ln \\Omega(E) \\approx S_1(E_1^{\\rm max}) + S_2(E - E_1^{\\rm max}).$$\n",
    " \n",
    "For large $N$, $\\Delta E_1 \\sim O(N^{1/2})$, so this is an extremely good approximation.\n",
    " \n",
    "Thus, $S$ is an additive (extensive) property (proportional to $N$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.6 Second law of thermodynamics\n",
    "\n",
    "Isolated chaotic or stochastic many-body systems evolve toward more probable (higher entropy) macrostates.\n",
    " \n",
    "The equilibrium macrostate is the state of maximum entropy.\n",
    "  \n",
    "**The change in entropy associated with *any process* in an *isolated* system is non-negative:**\n",
    " \n",
    "$$\\Delta S \\geq 0.$$\n",
    "\n",
    "For large systems, this law is *never* observably violated.\n",
    " \n",
    "*The force of probability is strong*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.7 Temperature, pressure, and chemical potential\n",
    "\n",
    "An isolated system (constant $N,V,E$) is *overwhelmingly* likely to be found in the macrostate that maximizes the entropy $S(E)$.\n",
    " \n",
    "What's the condition for thermal equilbrium between two weakly coupled subsystems that share $E$ (but not $N$ or $V$)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Maximize the total entropy $S(E) = S_1(E_1) + S_2(E - E_1)$ as a function of $E_1$:\n",
    " \n",
    "$$\\left( {{\\partial S(E)} \\over {\\partial E_1}} \\right) = 0 \n",
    " = \\left( {{\\partial S_1(E_1)} \\over {\\partial E_1}} \\right) + \\left( {{\\partial S_2(E - E_1)} \\over {\\partial E_1}} \\right)$$\n",
    "$$ = \\left( {{\\partial S_1(E_1)} \\over {\\partial E_1}} \\right) - \\left( {{\\partial S_2(E_2)} \\over {\\partial E_2}} \\right) = {1 \\over T_1} - {1 \\over T_2}.$$\n",
    " \n",
    "Here, the absolute *statistical temperature* $T$ is defined as:\n",
    " \n",
    "$${1 \\over T} = \\left( {{\\partial S(N,V,E)} \\over {\\partial E}} \\right)_{N,V} $$\n",
    " \n",
    "$T_1 = T_2$ *is the condition for thermal equilibrium between subsystems*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The inverse temperature $1/T$ is a logarithmic measure of how rapidly the number of microstates increases with increasing $E$, when $N$ and $E$ are held constant:\n",
    "  \n",
    "$$ {1 \\over T} = \\left( {{\\partial S(N,V,E)} \\over {\\partial E}} \\right)_{N,V}.$$\n",
    " \n",
    "Low $T$ (large $1/T$) implies a relatively large increase in entropy (probability) with the addition of given amount of energy.\n",
    " \n",
    "The flow of energy from high-temperature regions to low-temperature regions leads to an increase in the overall entropy, and is *overwhelmingly* probable.\n",
    " \n",
    "This is a consequence of the second law of thermodynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What's the condition for mechanical equilbrium between two subsystems that share $V$ (but not $N$ or $E$)?\n",
    " \n",
    "$$\\left( {{\\partial S_1(V_1)} \\over {\\partial V_1}} \\right) = \\left( {{\\partial S_2(V_2)} \\over {\\partial V_2}} \\right).$$\n",
    "\n",
    "This can be written:\n",
    "$${P_1 \\over T_1} = {P_2 \\over T_2},$$\n",
    " \n",
    "where the *statistical pressure* $P$ is defined via:\n",
    " \n",
    "$${P \\over T} = \\left( {{\\partial S(N,V,E)} \\over {\\partial V}} \\right)_{N,E}.$$\n",
    " \n",
    "$P$ is a logarithmic measure of how rapidly the number of available states increases with increasing $V$, when $N$ and $E$ are held constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What's the condition for diffusive equilbrium between two subsystems that share $N$ (but not $V$ or $E$)?\n",
    "\n",
    "$$\\left( {{\\partial S_1(N_1)} \\over {\\partial N_1}} \\right) = \\left( {{\\partial S_2(N_2)} \\over {\\partial N_2}} \\right).$$\n",
    "\n",
    "This can be written:\n",
    "$${\\mu_1 \\over T_1} = {\\mu_2 \\over T_2},$$ \n",
    "\n",
    "where the *chemical potential* $\\mu$ is defined via: \n",
    "\n",
    "$${\\mu \\over T} = - \\left( {{\\partial S(N,V,E)} \\over {\\partial N}} \\right)_{V,E}.$$\n",
    "\n",
    "$\\mu$ is a logarithmic measure of how rapidly the number of available states *decreases* with increasing $N$, when $V$ and $E$ are held constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.8 - First law of thermodynamics \n",
    "\n",
    "We can now write a general expression for how $S(N,V,E)$ varies under arbitrary (small) variations in $N$, $V$, and $E$:\n",
    "\n",
    "$$dS = \\left( {{\\partial S} \\over {\\partial E}} \\right)_{N,V} dE + \\left( {{\\partial S} \\over {\\partial V}} \\right)_{N,E} dV + \\left( {{\\partial S} \\over {\\partial N}} \\right)_{V,E} dN$$\n",
    "\n",
    "$$ = {1 \\over T} dE + {P \\over T} dV - {{\\mu} \\over T} dN.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This can be rearranged to give:\n",
    " \n",
    "$$dE = T dS - P dV + \\mu dN$$\n",
    "\n",
    "$$= dQ  + dW + dW_{\\rm chem}.$$\n",
    " \n",
    "Here $dQ = T dS$ is the heat (thermal energy) *added to* the system, and $dW$ and $dW_{\\rm chem}$ are, respectively, the mechanical and chemical work *done on* the system.\n",
    " \n",
    "This is just a statement of energy conservation, also called the *first law of thermodynamics* or the *fundamental thermodynamic identity*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.9 - Third law of thermodynamics \n",
    "\n",
    "In the limit of zero absolute temperature, a quantum system should settle into its unique lowest-energy ground state\n",
    " \n",
    "$$\\lim_{T \\rightarrow 0} \\Omega(N,V,E) = 1.$$\n",
    " \n",
    "This implies that the entropy goes to zero for $T \\rightarrow 0$ (the *third law of thermodynamics*):\n",
    "$$\\lim_{T \\rightarrow 0} S(N,V,E) = 0.$$\n",
    "Caveats:\n",
    "* The ground state may be degenerate.\n",
    "* Systems tend to fall out of equilibrium well before reaching $T = 0$ (glassy dynamics, non-ergodic behavior)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.0 - Canonical ensemble \n",
    "\n",
    "Consider a system A in thermal contact with a much larger system B ('heat bath') such that $T_B = T$ is constant.\n",
    " \n",
    "This defines the constant $N,V,T$ ensemble ('canonical' ensemble).\n",
    " \n",
    "The probability of finding system A in a specific energy eigenstate $i$ with energy $E_i$ is:\n",
    " \n",
    "$$P_i = {{\\Omega_A(E_i) \\Omega_B(E - E_i)} \\over {\\sum_j \\Omega_A(E_j) \\Omega_B(E - E_j)}} \n",
    " = {{\\Omega_B(E - E_i)} \\over {\\sum_j \\Omega_B(E - E_j)}}.$$\n",
    " \n",
    "Note that $\\Omega_A(E_i) = 1$ for any pure energy eigenstate $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$E_i << E$, so we can expand $\\ln \\Omega_B(E - E_i)$ around $E_i = 0$:\n",
    " \n",
    "$$\\ln \\Omega_B(E - E_i) \\approx \\ln \\Omega_B(E) - E_i \\left( {{\\partial \\ln \\Omega_B(E)} \\over {\\partial E}} \\right)_{N,V} = \\ln \\Omega_B(E) - \\beta E_i,$$\n",
    " \n",
    "where $\\beta = (k_B T)^{-1}$. Recall that $S(E) = k_B \\ln \\Omega_B(E)$ and $1/T = (\\partial S(E) / \\partial E)_{N,V}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We therefore have\n",
    "  \n",
    "$$P_i = \\frac{e^{-\\beta E_i}}{\\sum_j e^{-\\beta E_j}} = \\frac{e^{-\\beta E_i}}{Z}.$$\n",
    " \n",
    "This is the famous *Boltzmann distribution*, where $Z$ is the *partition function*:\n",
    "  \n",
    "$$Z(N,V,T) =  \\sum_j e^{-\\beta E_j}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$Z$ plays the same role in the $N,V,T$ ensemble that $\\Omega$ plays in the $N,V,E$ ensemble (it counts available states), and is a *very large* number if $N$ is large.\n",
    "\n",
    "To obtain an extensive quantity that's just a *large* number, we can define the *Helmholtz free energy* $A$:\n",
    "\n",
    "$$A(N,V,T) = -k_B T \\ln Z(N,V,T).$$\n",
    "\n",
    "$A$ plays an analogous role to $S$, and is *minimized* in thermal equilibrium for constant $N,V,T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From $Z$ and $A$, we can calculate all thermodynamic properties, for example the average energy,\n",
    "\n",
    "$$\\langle E \\rangle = \\sum_i E_i P_i = {1 \\over Z} \\sum_i E_i e^{-\\beta E_i} = - {1 \\over Z} {{\\partial Z} \\over {\\partial \\beta}} = - {{\\partial \\ln Z} \\over {\\partial \\beta}} = {{\\partial (\\beta A)} \\over {\\partial \\beta}},$$\n",
    "\n",
    "the entropy,\n",
    "\n",
    "$$S = {1 \\over T} \\left[\\langle E \\rangle - A \\right],$$\n",
    "\n",
    "and the heat capacity, \n",
    "$$C_V = {{\\partial \\langle E \\rangle } \\over {T}} = {1 \\over {k_B T^2}} {{\\partial^2 \\ln Z} \\over {\\partial \\beta^2}}. $$\n",
    "\n",
    "The canonical ensemble is generally *much* more convenient for calculations than the microcanonical ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.1 - Planck radiation law \n",
    "\n",
    "The energy levels of a 1D harmonic oscillator (neglecting zero-point energy) are $E_n = n \\hbar \\omega, \\ \\ n=0,\\infty$, so the canonical partition function is\n",
    "\n",
    "$$Z = \\sum_{n=0}^\\infty e^{- \\beta n \\hbar \\omega} = \\sum_{n=0}^\\infty \\left( e^{-\\beta \\hbar \\omega} \\right)^n\n",
    "= {1 \\over {1 - e^{-\\beta \\hbar \\omega} }}.$$\n",
    "\n",
    "Here we've used the identity $1 / (1-x) = \\sum_{n=0}^\\infty x^n$ for $x < 1$.\n",
    "\n",
    "Thus, the average energy is\n",
    "\n",
    "$$\\left\\langle E \\right \\rangle = - {1 \\over Z} {{\\partial Z} \\over {\\partial \\beta}}\n",
    " = {{\\hbar \\omega} \\over {e^{\\beta \\hbar \\omega} - 1}}.$$\n",
    "\n",
    "*This is the Planck radiation law!*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
