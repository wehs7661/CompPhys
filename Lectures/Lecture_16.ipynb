{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-100899e0deea9789",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 16: Free energy calculations\n",
    "\n",
    "## Physics 7810, Spring 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 16.1 - Thermodynamic integration\n",
    "\n",
    "Free energy calculations are central to the theory of phase transitions, as the equilibrium state of a system in thermodynamic equilibrium corresponds to a minimum (or maximum) of the free energy appropriate to a given set of thermodynamic conditions. For example, the entropy $S$ is maximized for a closed system (constant $N,V,E$) in equilibrium, while for a system in thermal equilibrium with a reservior (but otherwise closed, i.e., constant $N,V,T$) the appropriate thermodynamic potential is the Helmholtz free energy $F = E - TS$, and for a system at constant pressure and temperature the Gibbs free energy $G = E - TS + PV$ is minimized in equilibrium.\n",
    "\n",
    "For example, to determine which of two phases (denoted $A$ and $B$) of a substance is stable at a given temperature $T$ and density $\\rho = N/V$, we can compare the Helmholtz free energies $F_A$ and $F_B$ of the two phases to see which is smaller (of course, the situation becomes more complicated if we happen to pick a density within a two-phase coexistence region, as you've already seen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sadly, it isn't possible to measure the free energy (or entropy) directly in a computer simulation, because such quantities aren't simple averages of functions of the phase space variables ($E$ and $P$ are, but $S$ isn't). Free energies are instead related to the volume in phase space accessible to a system under given thermodynamic conditions (the *multiplicity* or *partition function*).\n",
    "\n",
    "For example, in classical statistical mechanics, the Helmholtz free energy is directly related to the canonical partition function $Z(N,V,T)$,\n",
    "\n",
    "$$\n",
    "F(N,V,T) = - k_B T \\ln Z(N,V,T)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= - k_B T \\ln \\left( \\frac{1}{h^{dN} N!} \n",
    "\\int d{\\bf p}^N d{\\bf r}^N \\exp \\left[ - \\beta H({\\bf p}^N, {\\bf r}^N) \\right] \\right),\n",
    "$$\n",
    "\n",
    "where $d$ is the spatial dimensionality. Clearly, $F$ (or $S$, $G$, ...) isn't a simple canonical ensemble average, and cannot be measured directly in a computer simulation, as it depends on the available phase space volume. In other words, to compute quantities like the average energy or pressure it suffices to know the *relative* weight of distinct microstates, and to sample from the appropriate (e.g., canonical) distribution, but to calculate free energies requires knowing the overall *normalization factor* (the partition function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In fact, the same problem arises in the real world: free energies cannot be measured directly, but *derivatives* of the free energy can, via thermodynamic relations such as\n",
    "\n",
    "$$\n",
    "\\left( \\frac{\\partial F}{\\partial V} \\right)_{N,T} = - P\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\left( \\frac{\\partial \\beta F}{\\partial \\beta} \\right)_{V,N} = E,\n",
    "$$\n",
    "\n",
    "where $\\beta = (k_B T)^{-1}$.\n",
    "\n",
    "Because the pressure $P$ and energy $E$ are mechanical properties, they can be measured directly in a simulation. Thus, for example, we can compute the free energy of a system at a given $T$ and $\\rho$ by finding a reversible path in the $V-T$ plane that connects the given state to a state with known free energy. The change in $F$ along that path can then be evaluated by *thermodynamic integration*, i.e., integration of the above equations, making use of the average $P$ and $E$ measured in simulations at a number of values of $V$ and/or $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are very few thermodynamic states for which the exact free energy is known, e.g., the ideal gas or the harmonic (Einstein) crystal, but these reference states are very useful in practice. A well-known application of thermodynamic integration is the calculation of the free energy of a liquid via integration of the equation of state from the low-density ideal gas reference state, making use of $(\\partial F / \\partial V)_{N,T} = - P$.\n",
    "\n",
    "In this case, it's not really necessary to go all the way to the ideal gas, but one should reach states that are dilute enough to ensure that the free energy can be calculated accurately from the first few terms in the virial expansion for the compressibility factor $PV/(N k_B T)$, or from direct calculation of the chemical potential (e.g., using the Widom particle insertion method).\n",
    "\n",
    "For crystalline solids, the absolute free energy can be calculated by thermodynamic integration to an Einstein crystal reference state, by 'adiabatically' converting the real (anharmonic) crystal into a harmonic solid. A combination of these two methods can then be used to trace out the solid-liquid coexistence line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In computer simulations, we're not limited to to using physical thermodynamic integration paths, as the example of the Einstein crystal integration method makes clear. We have the freedom to use any parameters in the potential energy function as thermodynamic variables.\n",
    "\n",
    "For example, if we know the free energy of the Lennard-Jones (LJ) fluid, we can calculate the free energy of the Stockmayer fluid (LJ particles with embedded point dipoles) by calculating the reversible thermodynamic work required to switch on the dipolar interactions, starting from the LJ fluid.\n",
    "\n",
    "The general formalism for calculation such free energy differences is a powerful method known as the *Kirkwood coupling parameter method* (sometimes also called the $\\lambda$-integration method)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Consider an N-particle system with a potential energy function $U({\\bf r}^N)$, and assume that $U$ depends linearly on a coupling parameter $\\lambda$ such that, for $\\lambda = 0$, $U$ is the potential energy of a *reference* system (system I), while for $\\lambda = 1$, the potential energy of the system of interest (system II) is recovered,\n",
    "\n",
    "$$\n",
    "U(\\lambda) = (1 - \\lambda) U_\\mathrm{I} + \\lambda U_\\mathrm{II}\n",
    "= U_\\mathrm{I} + \\lambda (U_\\mathrm{II} - U_\\mathrm{I})\n",
    "$$\n",
    "\n",
    "In the example above, system I is the LJ fluid, and system II is the Stockmayer fluid. In what follows, we assume that the free energy of system I is known (either analytically or numerically).\n",
    "\n",
    "It is very important to note, however, that for many purposes (e.g., computing phase diagrams) only the *free energy difference* between two states is required, and it's not necessary to determine the *absolute free energy* of either state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The partition function for a 3D system with potential energy $U(\\lambda)$ (corresponding to a specific value of $\\lambda$) is\n",
    "\n",
    "$$\n",
    "Z(N,V,T,\\lambda) = \\frac{1}{\\Lambda^{3N} N!} \n",
    "\\int d{\\bf r}^N \\exp \\left[ - \\beta U(\\lambda) \\right],\n",
    "$$\n",
    "\n",
    "and the corresponding Helmholtz free energy is\n",
    "\n",
    "$$\n",
    "F(N,V,T,\\lambda) = - \\frac{1}{\\beta} \\ln Z(N,V,T,\\lambda).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The derivative of $F(\\lambda)$ with respect to $\\lambda$ can be written as an ensemble average,\n",
    "\n",
    "$$\n",
    "\\left( \\frac{\\partial F(\\lambda)}{\\partial \\lambda} \\right)_{N,V,T}\n",
    "= - \\frac{1}{\\beta} \\frac{\\partial}{\\partial \\lambda} \\ln Z(N,V,T,\\lambda)\n",
    "= - \\frac{1}{\\beta} \\frac{1}{Z(N,V,T,\\lambda)} \\frac{\\partial Z(N,V,T,\\lambda)}{\\partial \\lambda}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= - \\frac{1}{\\beta} \\frac{1}{Z(N,V,T,\\lambda)} \\frac{1}{\\Lambda^{3N} N!} \\frac{\\partial}{\\partial \\lambda}\n",
    "\\int d{\\bf r}^N \\exp \\left[ - \\beta U(\\lambda) \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "= - \\frac{1}{\\beta} \\frac{1}{Z(N,V,T,\\lambda)} \\frac{1}{\\Lambda^{3N} N!} \n",
    "\\int d{\\bf r}^N \\left( - \\beta \\frac{\\partial U(\\lambda)}{\\partial \\lambda} \\right) \\exp \\left[ - \\beta U(\\lambda) \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{\\int d{\\bf r}^N \\left( \\frac{\\partial U(\\lambda)}{\\partial \\lambda} \\right) \\exp \\left[ - \\beta U(\\lambda) \\right]}{\\int d{\\bf r}^N \\exp \\left[ - \\beta U(\\lambda) \\right]}\n",
    "= \\left\\langle \\frac{\\partial U(\\lambda)}{\\partial \\lambda} \\right\\rangle_\\lambda,\n",
    "$$\n",
    "\n",
    "where $\\langle ... \\rangle_\\lambda$ denotes an ensemble average for a system with potential energy $U(\\lambda)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The free energy difference between systems II and I can be obtained by integrating this result,\n",
    "\n",
    "$$\n",
    "F_\\mathrm{II}(N,V,T) - F_\\mathrm{I}(N,V,T) = F(\\lambda = 1) - F(\\lambda = 0)\n",
    "= \\int_0^1 d \\lambda \\left\\langle \\frac{\\partial U(\\lambda)}{\\partial \\lambda} \\right\\rangle_\\lambda.\n",
    "$$\n",
    "\n",
    "This is an extremely useful result, because it expresses the free energy difference in terms of an ensemble average that can be easily measured in a computer simulation. The intergral can then be evaluated numerically, e.g., using Gaussian quadrature, with $\\langle \\partial U(\\lambda) / \\partial \\lambda \\rangle_\\lambda$ measured at pre-defined values of $\\lambda$.\n",
    "\n",
    "Thermodynamic integration along artifical pathways is often used to compute the difference in excess free energy  between similar but distinct molecules ('mutation'). This sort of calculation is widely used in biomolecular modeling and drug design, for example to compute the effect of a chemical substitution on the binding free energy of a molecule to an enzyme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 16.2 - Bennett acceptance ratio method\n",
    "\n",
    "The Bennett acceptance ratio (BAR) method is a scheme for estimating the free energy difference between two systems (denoted 0 and 1) from two simulations: one of system 0 and one of system 1. This scheme is based on the identity\n",
    "\n",
    "$$\n",
    "\\frac{Z_0}{Z_1} = \\frac{Z_0 \\int d{\\bf r}^N \\alpha({\\bf r}^N) \\exp \\left[ - \\beta (U_0 + U_1) \\right]}{Z_1 \\int d{\\bf r}^N \\alpha({\\bf r}^N) \\exp \\left[ - \\beta (U_0 + U_1) \\right]}\n",
    "= \\frac{\\langle \\alpha \\exp (- \\beta U_0) \\rangle_1}{\\langle \\alpha \\exp (- \\beta U_1) \\rangle_0},\n",
    "$$\n",
    "\n",
    "which is true for an arbitrary function $\\alpha({\\bf r}^N)$, and where, for example,\n",
    "\n",
    "$$\n",
    "\\langle \\alpha \\exp (- \\beta U_0) \\rangle_1 \\equiv \\frac{1}{\\Lambda^{3N} N!} \\frac{1}{Z_1}\n",
    "\\int d{\\bf r}^N \\left[ \\alpha \\exp (- \\beta U_0) \\right] \\exp (- \\beta U_1)\n",
    "$$\n",
    "\n",
    "If this ratio can be calculated accurately, then the free energy difference between the two systems can be obtained directly, from\n",
    "\n",
    "$$\n",
    "\\beta \\Delta F = \\beta F_0 - \\beta F_1 = \\ln (Z_0 / Z_1).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the BAR method, the function $\\alpha$ is chosen to maximize the statistical accuracy of this free energy difference. This is achieved by estimating the statistical error in the numerator and denominator in the above equation for $Z_0 / Z_1$, and using variational calculus to minimize the error with respect to the functional form of $\\alpha({\\bf r}^N)$, which yields\n",
    "\n",
    "$$\n",
    "\\alpha = \\mathrm{const} \\times \\left( \\frac{Z_0}{n_0} \\exp(- \\beta U_1) + \\frac{Z_1}{n_1} \\exp(- \\beta U_0) \\right)^{-1},\n",
    "$$\n",
    "\n",
    "where $n_0$ and $n_1$ are the number of statistically independent from states 0 and 1, respectively. Plugging this optimal function into the above equation gives\n",
    "\n",
    "$$\n",
    "\\frac{Z_0}{Z_1}\n",
    "= \\frac{\\langle f_\\mathrm{FD} (U_0 - U_1 + C) \\rangle_1}{\\langle f_\\mathrm{FD} (U_1 - U_0 + C) \\rangle_0} \\exp(\\beta C),\n",
    "$$\n",
    "\n",
    "where $f_\\mathrm{FD}(x) = 1 / (1 + \\exp (x))$ is the Fermi-Dirac function, and $C \\equiv \\ln [(Z_0 n_1)/(Z_1 n_0)]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "At first sight, this choice of $C$ seems problematic because it depends on the very thing we want to calculate, namely the ratio of partition functions $Z_0/Z_1$. In practice, $C$ is determined by imposing a self-consistency requirement.\n",
    "\n",
    "We can estimate the averages in the above equation for $Z_0/Z_1$ from simulations via\n",
    "\n",
    "$$\n",
    "\\langle f_\\mathrm{FD} (U_0 - U_1 + C) \\rangle_1 = \\frac{1}{n_1} \\sum_1 f_\\mathrm{FD}^1 (U_0 - U_1 + C)\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\langle f_\\mathrm{FD} (U_1 - U_0 + C) \\rangle_0 = \\frac{1}{n_0} \\sum_0 f_\\mathrm{FD}^0 (U_0 - U_1 + C),\n",
    "$$\n",
    "\n",
    "where $\\sum_0$ and $\\sum_1$ denote sums over configurations sampled in simulations of systems 0 and 1, respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With these estimates, we obtain an expression the free energy difference,\n",
    "\n",
    "$$\n",
    "\\beta \\Delta F = \\ln \\frac{\\sum_1 f_\\mathrm{FD}^1 (U_0 - U_1 + C)}{\\sum_0 f_\\mathrm{FD}^0 (U_0 - U_1 + C)}\n",
    "- \\ln(n_1/n_0) + \\beta C,\n",
    "$$\n",
    "\n",
    "whereas the optimal choice for $C$ gives\n",
    "\n",
    "$$\n",
    "\\beta \\Delta F = - \\ln(n_1/n_0) + \\beta C.\n",
    "$$\n",
    "\n",
    "These two expressions are only consistent if\n",
    "\n",
    "$$\n",
    "\\sum_1 f_\\mathrm{FD}^1 (U_0 - U_1 + C) = \\sum_0 f_\\mathrm{FD}^0 (U_0 - U_1 + C).\n",
    "$$\n",
    "\n",
    "In practice, $C$ is varied until this self-consistency relation is satisfied, and then inserted into the above equation to obtain the free energy difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 16.3 - Umbrella sampling and the weighted histogram analysis method\n",
    "\n",
    "*Umbrella sampling* is a *biased sampling* method that can be used to measure the free energy of a system as a function of a collective variable $Q({\\bf r}^N)$, which could be an order parameter or reaction coordinate, for example.\n",
    " \n",
    "The basic idea is to measure the probability density $\\rho(Q)$, defined (in the canonical ensemble) as\n",
    "\n",
    "$$\n",
    "\\rho(Q) = \\langle \\delta [ Q - Q({\\bf r}^N) ] \\rangle = \\frac{1}{Z(N,V,T)}\n",
    "\\int d {\\bf r}^N\\ \\delta [ Q - Q({\\bf r}^N) ]\\ e^{- \\beta U({\\bf r}^N)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{Z(Q,N,V,T)}{Z(N,V,T)},\n",
    "$$\n",
    "\n",
    "where $Z(N,V,T) = \\int d {\\bf r}^N e^{- \\beta U({\\bf r}^N)}$. $Z(Q,N,V,T)$ can be regarded as the partition function for a restricted ensemble in which $Q$ is an additional constrained thermodynamic parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we knew $\\rho(Q)$ for all $Q$, then we could obtain the free energy $F$ as a function of $Q$ (to within an additive constant) from\n",
    "\n",
    "$$\n",
    "F(Q) = - k_B T \\ln \\rho(Q).\n",
    "$$\n",
    "\n",
    "The applicability of this approach is limited to regions where the Boltzmann factor is large (near the equilibrium value of $Q$), because the statistical error in $\\rho(Q)$ is otherwise very large due do limited statistical sampling.\n",
    "\n",
    "To overcome this limitation, we introduce a biasing potential $U^\\prime(Q)$ to constrain $Q$ to some specified range ('window') of $Q$. For example, a harmonic biasing potential is often used,\n",
    "\n",
    "$$\n",
    "U^\\prime(Q) = \\frac{1}{2} k_Q (Q - Q_0)^2,\n",
    "$$\n",
    "   \n",
    "where $k_Q$ is an effective spring constant, and $Q_0$ specifies the location of the sampling window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The probability density of $Q$ with a biasing potential $U^\\prime(Q)$ is\n",
    "\n",
    "$$\n",
    "\\rho^\\prime(Q) = \\frac{1}{Z^\\prime(N,V,T)} \\int d {\\bf r}^N \\ \\delta [ Q - Q({\\bf r}^N) ]\\ e^{- \\beta [U({\\bf r}^N) + U^\\prime(Q({\\bf r}^N))]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{1}{Z^\\prime(N,V,T)} e^{- \\beta U^\\prime(Q)} \\int d {\\bf r}^N \\ \\delta [ Q - Q({\\bf r}^N) ]\\ e^{- \\beta U({\\bf r}^N)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{Z(N,V,T)}{Z^\\prime(N,V,T)} e^{- \\beta U^\\prime(Q)} \\rho(Q),\n",
    "$$\n",
    "\n",
    "which can be inverted to obtain\n",
    "\n",
    "$$\n",
    "\\rho(Q) = \\frac{Z^\\prime}{Z} e^{\\beta U^\\prime(Q)} \\rho^\\prime(Q).\n",
    "$$\n",
    " \n",
    "Thus, the probability density $\\rho(Q)$ can be obtained to within a multiplicative constant $Z^\\prime/Z$ from a measurement of the biased probability density $\\rho^\\prime(Q)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using this result, the free energy $F(Q)$ can be obtained (to within an additive constant) over a limited range of $Q$, determined by the specific biasing potential\n",
    " \n",
    "By combining probability densities obtained by biased sampling within a number of overlapping windows, one can obtain $\\rho(Q)$ and hence $F(Q) = - k_B \\ln \\rho(Q)$ over an arbitrary range of $Q$.\n",
    " \n",
    "The individual probability densities are combined so as to minimize the variance in the overall estimate for $\\rho(Q)$, a procedure called the *weighted histogram analysis method* (WHAM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the weighted histogram analysis method, we consider a series of $n$ biased probability distributions $\\rho_i(Q)$ with biasing potentials $U_i^\\mathrm{bias}(Q)$, where $i = 1,n$. In a simulation, each of these probability distributions can be estimated by measuring a histogram $h_i(Q)$, which counts the number of times that a system with potential energy function $U({\\bf r}^N) + U_i^\\mathrm{bias}(Q({\\bf r}^N))$ has a value of the order parameter between $Q$ and $Q + \\Delta Q$, where $\\Delta Q$ is the histogram bin width.\n",
    "\n",
    "In terms of these histograms, the biased probability distributions are given by\n",
    "\n",
    "$$\n",
    "\\rho_i(Q) \\Delta Q = \\frac{\\langle h_i(Q) \\rangle}{m_i},\n",
    "$$\n",
    "\n",
    "where the angle brackets denote an ensemble average, and $m_i$ is the total number of points (samples) collected in histogram $i$, assumed to be statistically independent (e.g., obtained by subsampling from a set of $Q$ values measured in a simulation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In a simulation of finite duration, there will be statistical uncertainty in the estimated distributions $\\rho_i^\\mathrm{est}(Q)$. If we assume that the number of points in a given bin is determined by a Poisson distribution (appropriate for statistically independent events), then the variance in $\\rho_i^\\mathrm{est}(Q) \\Delta Q$ is given by\n",
    "\n",
    "$$\n",
    "\\frac{\\langle h_i(Q)^2 \\rangle - \\langle h_i(Q) \\rangle^2}{m_i^2} \n",
    "= \\frac{\\langle h_i(Q) \\rangle}{m_i^2}\n",
    "= \\frac{\\rho_i(Q) \\Delta Q}{m_i}.\n",
    "$$\n",
    "\n",
    "Recall that the variance of the Poisson distribution is equal to the mean. In what follows we will choose units such that $\\Delta Q = 1$ in order to simplify the notation.\n",
    "\n",
    "Once we have measured a set of estimated histograms, we can combine them to obtain an estimate of the original probability density $\\rho(Q)$ and the corresponding free energy $F(Q)$. We can in principle obtain $\\rho(Q)$ from a *single* biased distribution as described above, i.e.,\n",
    "\n",
    "$$\n",
    "\\rho(Q) = \\frac{Z_i}{Z} e^{\\beta U_i^\\mathrm{bias}(Q)} \\rho_i^\\mathrm{est}(Q),\n",
    "$$\n",
    "\n",
    "but this will only work over a very limited range of $Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To obtain an estimate $\\rho(Q)$ over a broad range of $Q$ values, we construct a linear combination of single histogram estimates,\n",
    "\n",
    "$$\n",
    "\\rho^\\mathrm{est}(Q) = \\sum_{i = 1}^N w_i(Q) \\frac{Z_i}{Z} e^{\\beta U_i^\\mathrm{bias}(Q)} \\rho_i^\\mathrm{est}(Q),\n",
    "$$\n",
    "\n",
    "where $w_i(Q)$ is a weight function that will be determined by minimizing the variance in $\\rho^\\mathrm{est}(Q)$, subject to the normalization condition\n",
    "\n",
    "$$\n",
    "\\sum_{i = 1}^N w_i(Q) = 1.\n",
    "$$\n",
    "\n",
    "Note that the partition function ratios $Z_i / Z$ are also still unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Because the fluctuations in distinct simulations are uncorrelated, the variance in $\\rho^\\mathrm{est}(Q)$ is given by\n",
    "\n",
    "$$\n",
    "\\langle \\rho^\\mathrm{est}(Q)^2 \\rangle - \\langle \\rho^\\mathrm{est}(Q) \\rangle^2\n",
    "= \\sum_{i = 1}^n w_i^2(Q) \\left( \\frac{Z_i}{Z} \\right)^2 e^{2 \\beta U_i^\\mathrm{bias}(Q)}\n",
    "\\left[ \\langle \\rho_i^\\mathrm{est}(Q)^2 \\rangle - \\langle \\rho_i^\\mathrm{est}(Q) \\rangle^2 \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\sum_{i = 1}^n w_i^2(Q) \\left( \\frac{Z_i}{Z} \\right)^2 e^{2 \\beta U_i^\\mathrm{bias}(Q)}\n",
    "\\frac{\\rho_i^\\mathrm{est}(Q)}{m_i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\rho(Q) \\sum_{i = 1}^n w_i^2(Q) \\frac{Z_i}{Z} e^{\\beta U_i^\\mathrm{bias}(Q)} \\frac{1}{m_i}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The weights are determined by differentiating the variance with respect to $w_i$ subject to the constraint $\\sum_{i = 1}^n w_i = 1$, which gives\n",
    "\n",
    "$$\n",
    "w_i(Q) = \\alpha e^{-\\beta U_i^\\mathrm{bias}(Q)} m_i \\frac{Z}{Z_i},\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is an undetermined multiplier, fixed by the normalization condition to be\n",
    "\n",
    "$$\n",
    "\\alpha = \\left( \\sum_{i = 1}^n e^{-\\beta U_i^\\mathrm{bias}(Q)} m_i \\frac{Z}{Z_i} \\right)^{-1}.\n",
    "$$\n",
    "\n",
    "Inserting these weights into the estimate for $\\rho(Q)$ gives\n",
    "\n",
    "$$\n",
    "\\rho^\\mathrm{est}(Q) = \\frac{\\sum_{i = 1}^n h_i(Q)}{\\sum_{i = 1}^n e^{-\\beta U_i^\\mathrm{bias}(Q)} m_i \\frac{Z}{Z_i}}.\n",
    "$$\n",
    "\n",
    "Note that we still need to determine the partition functions $Z_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The partition function $Z_i$ is determined by returning to the definition of $Z_i$,\n",
    "\n",
    "$$\n",
    "Z_i = \\int d{\\bf r}^N e^{-\\beta [U + U_i^\\mathrm{bias}(Q)]}\n",
    "= \\int dQ  Z \\rho(Q) e^{-\\beta U_i^\\mathrm{bias}(Q)},\n",
    "$$\n",
    "\n",
    "where we have made use of the definition of $\\rho(Q)$,\n",
    "\n",
    "$$\n",
    "\\rho(Q) = \\frac{1}{Z} \\int d{\\bf r}^N \\delta[Q - Q({\\bf r}^N)] e^{- \\beta U({\\bf r}^N)}.\n",
    "$$\n",
    "\n",
    "Inserting the optimal multiple-histogram estimate for $\\rho(Q)$ into the above equation for $Z_i$ then gives\n",
    "\n",
    "$$\n",
    "Z_i = \\int dQ e^{-\\beta U_i^\\mathrm{bias}(Q)} \\frac{\\sum_{i = 1}^n h_i(Q)}{\\sum_{i = 1}^n e^{-\\beta U_i^\\mathrm{bias}(Q)} \\frac{m_i}{Z_i}}\n",
    "\\approx \\sum_Q e^{-\\beta U_i^\\mathrm{bias}(Q)} \\frac{\\sum_{i = 1}^n h_i(Q)}{\\sum_{i = 1}^n e^{-\\beta U_i^\\mathrm{bias}(Q)} \\frac{m_i}{Z_i}},\n",
    "$$\n",
    "\n",
    "where in the final step I've explicitly indicated that the partition function is numerically evaluated as a discrete sum over histogram bins. We thus have a set of implicit equations for the $Z_i$ that must be solved self-consistently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In practice, we only need the ratios of the $Z_i$, not their absolute values, so the value of one  $Z_i$ (say $Z_1$) can be set to a constant value (say 1) and the nonlinear set of equations\n",
    "\n",
    "$$\n",
    "Z_i = \\sum_Q e^{-\\beta U_i^\\mathrm{bias}(Q)} \\frac{\\sum_{i = 1}^n h_i(Q)}{\\sum_{i = 1}^n e^{-\\beta U_i^\\mathrm{bias}(Q)} \\frac{m_i}{Z_i}}\n",
    "$$\n",
    "\n",
    "can be solved iteratively for the remaining $Z_i$ until a self-consistent solution is found. Given this solution for the $Z_i$, $\\rho^\\mathrm{est}(Q)$ is then fully determined, and an optimal estimate of the free energy is then obtained from\n",
    "\n",
    "$$\n",
    "F^\\mathrm{est}(Q) = - k_B T \\ln \\rho^\\mathrm{est}(Q),\n",
    "$$\n",
    "\n",
    "and uncertainties in the distribution function and free energy can be obtained from the variance estimate described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By way of illustration, Frenkel & Smit consider the example of an ideal gas in an external potential with a hard wall,\n",
    "\n",
    "$$\n",
    "u(z) = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "z, & z > 0 \\\\\n",
    "\\infty, & z \\leq 0\n",
    "\\end{array}\n",
    "\\right..\n",
    "$$\n",
    "\n",
    "For this system, the probability density as a function of $z$ is given by the barometric distribution, $\\rho(z) \\propto \\exp(- \\beta u(z))$. Overlapping windows defined by the following 'hard-wall' biasing potential are used,\n",
    "\n",
    "$$\n",
    "U_i^\\mathrm{bias}(z) = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\infty, & z < z_i^\\mathrm{min} \\\\\n",
    "0, & z_i^\\mathrm{min} \\leq z < z_i^\\mathrm{max} \\\\\n",
    "\\infty, & z \\geq z_i^\\mathrm{max}\n",
    "\\end{array}\n",
    "\\right.,\n",
    "$$\n",
    "\n",
    "Where only neighboring windows are allowed to overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Probability of finding an ideal gas particle in an external potential at position $z$. Histograms collected within individual windows are shown on the left, while the figure on the right shows the full distribution function obtained from WHAM.\n",
    "\n",
    "<img src=\"images/Frenkel_Fig_7.3.png\" alt=\"Drawing\" style=\"width: 1000px;\">\n",
    "\n",
    "Figure from *Understanding Molecular Simulation: From Algorithms to Applications*, by Daan Frenkel and Berend Smit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66620da88b06fd9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 16.3 - Multiple Bennett acceptance ratio method\n",
    "\n",
    "The multiple Bennett acceptance ratio (MBAR) method is a generalization of the Bennett acceptance ratio method to sets of multiple states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
